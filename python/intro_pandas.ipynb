{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series e DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "#Series\n",
    "# Series -> prendo in ingresso una lista di valori \n",
    "# Series -> pd.Series(data, index?)\n",
    "pds = pd.Series([1,2,3,4,5])\n",
    "# print(pds)\n",
    "# print(pds[2])\n",
    "print(pds[1:3])\n",
    "\n",
    "# Nelle series è possibilie esplicitare gli indici\n",
    "pdsi = pd.Series([1,2,3,4,5], index=list('abcde'))\n",
    "# pdsi = pd.Series([1,2,3,4,5], ['a','b','c','d','e'])\n",
    "# print(pdsi)\n",
    "# print(pdsi['c'])\n",
    "print(pdsi['b':'d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series e DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Esistono due metodi diversi nelle Series che permettono \n",
    "# l'accesso a un sottoinsieme di dati\n",
    "# loc[] -> usa le etichette\n",
    "# iloc[] -> usa gli indici (slicing)\n",
    "\n",
    "pdsi = pd.Series([1,2,3,4,5], index=['1990','1991','1992','1993','1994'])\n",
    "\n",
    "print(pdsi.iloc[3])\n",
    "print(pdsi.loc[\"1991\"])\n",
    "\n",
    "print(pdsi.iloc[1:3])\n",
    "print(pdsi.loc[\"1990\": \"1993\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "# Il DataFrame è una struttura di dati tabellari bidimensionali\n",
    "# DataFrame -> prendono in ingresso un dizionaro o un ndArray\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "matrix = np.random.randint(0,100, [4,5])\n",
    "# print(matrix)\n",
    "# pd.DataFrame(matrix)\n",
    "\n",
    "# Posso esplicitare intestazioni di riga o di colonna nella\n",
    "# rappresentazione del dato di un DataFrame\n",
    "pd.DataFrame(matrix, \n",
    "                index=['Roma', 'Milano','Torino',  'Napoli'],\n",
    "                columns=['2020', '2021', '2022', '2023', '2024'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# DataFrame -> prendono in ingresso un dizionaro o un ndArray\n",
    "# Dizionario composto da chiave/valore\n",
    "data = {\n",
    "        'data_analyst': [10,20,30], \n",
    "        'cybersecurity': [40, 50, 60],\n",
    "        'developer': [70, 80, 90],\n",
    "        'cloud_developer': [10, 40, 70]\n",
    "        }\n",
    "print(data)\n",
    "\n",
    "# Posso esplicitare intestazioni di riga per\n",
    "# rappresentazione del dato di un DataFrame\n",
    "# le intestazioni di colonna vengono prese dalla chiave del dizionario\n",
    "pd.DataFrame(data, index=['2020', '2021', '2022'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# il DataFrame è un formato ottimizzato per la lettura di dati \n",
    "# tabellari bidimensionali come per Excel e SQL\n",
    "\n",
    "iris = pd.read_csv('iris.csv') # importo un CSV in un DataFrame\n",
    "type(iris) # leggo il tipo di dato importato (DataFrame)\n",
    "iris = pd.read_csv('iris.csv', header=None) # escludo l'header\n",
    "iris = pd.read_csv('iris.csv', names=['C1', 'C2', 'C3','C4','C5']) # diamo dei nomi alle intestazioni di colonna\n",
    "iris = pd.read_csv('iris.csv', header=0) # numero di riga in cui si trova l'header\n",
    "iris = pd.read_csv('iris.csv', usecols=[0, 1, 4]) # selezione solo alcune colonne\n",
    "iris.shape # stampa la forma del dataFrame\n",
    "iris.head(7) # ritorna le prime n righe di un DF -> di default sono 5\n",
    "iris.tail(3) # ritorna le ultime n righe di un DF -> di default sono 5\n",
    "\n",
    "print(iris.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv') # importo un CSV in un DataFrame\n",
    "\n",
    "iris.columns # restituisce i metadati delle colonne\n",
    "iris.index # restituisce i metadati delle righe\n",
    "iris.values # restituisce solo i dati in formato ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv') # importo un CSV in un DataFrame\n",
    "stats = iris.describe() # restituisce un sommario di dati statistici del dataframe\n",
    "\n",
    "stats.to_csv('iris_stats.csv') # Salvare un dataframe in un CSV\n",
    "# Per salvare nel formato proprietario Excel dovete installare la dipendenza openpyxl\n",
    "# pip install openpyxl\n",
    "stats.to_excel('iris_stats.xlsx', sheet_name='Foglio Stats') # Salvare un dataframe in un foglio Excel\n",
    "stats.to_json('iris_stats.json') # Salvare un dataframe in un JSON\n",
    "# Per salvare nel formato proprietario MArkDown dovete installare la dipendenza tabulate\n",
    "# pip install tabulate\n",
    "stats.to_markdown('iris_stats.md') # Salvare un dataframe in un formato MarkDown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dehors = pd.read_csv('Comune-di-Firenze---Dehors.csv', sep=';') \n",
    "\n",
    "dehors.sample(5) # seleziona random n istanze da un Data Frame\n",
    "dehors.sample(frac=0.1) # seleziona un 10% di dati dal Data Frame\n",
    "\n",
    "filtro = dehors.MQ == '18'\n",
    "# print(filtro)\n",
    "\n",
    "selezione = dehors.loc[filtro]\n",
    "\n",
    "filtro2 = dehors.MQ >= '18'\n",
    "selezione = dehors.loc[filtro2]\n",
    "selezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Comune-di-Roma-Capitale---Elenco-delle-strutture-ricettive.csv'\n",
    "\n",
    "# Importo in un DataFrame il CSV, imposto come delimitatore il carattere ';'\n",
    "# in sostituzione del valore di default (',') in più imposto l'encoding dei caratteri\n",
    "# esplicitando la lingua italiana\n",
    "strutture = pd.read_csv(file_path, delimiter=';', encoding='ISO-8859-1')\n",
    "type(strutture) # Stampo il tipo di dato\n",
    "strutture.shape # Stampo numero di righe e colonne del dato\n",
    "strutture.columns # stampo una lista di colonne del dataframe\n",
    "strutture.head() # Stampo le prime 5 righe del dataFrame\n",
    "strutture.describe() # restituisce un sommario di dati statistici numerici del dataframe\n",
    "\n",
    "strutture.dtypes # Stampo il tipo di dato per ogni colonna\n",
    "strutture.info() # Stampo un resoconto dettagliato sul DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Comune-di-Roma-Capitale---Elenco-delle-strutture-ricettive.csv'\n",
    "# Con gli attributi nrows e usecols possiamo specificare il numero di righe \n",
    "# e il numero di colonne che vogliamo leggere ed inserire in un DataFrame\n",
    "strutture = pd.read_csv(\n",
    "                file_path, \n",
    "                delimiter=';', \n",
    "                encoding='ISO-8859-1',\n",
    "                nrows=7,\n",
    "                usecols=range(5)\n",
    "                )\n",
    "print(strutture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Comune-di-Roma-Capitale---Elenco-delle-strutture-ricettive.csv'\n",
    "\n",
    "strutture = pd.read_csv(\n",
    "                file_path, \n",
    "                delimiter=';', \n",
    "                encoding='ISO-8859-1'\n",
    "                )\n",
    "strutture.head(10)\n",
    "strutture[5:15]\n",
    "strutture['Municipio']\n",
    "strutture.loc[5]\n",
    "strutture.loc[5, 'Indirizzo']\n",
    "strutture.loc[:10]\n",
    "strutture.loc[:10, 'Tipologia':'Indirizzo']\n",
    "strutture.loc[:, 'Municipio': 'Denominazione']\n",
    "# Dataframe.loc[righe, colonne]\n",
    "\n",
    "strutture.iloc[3:13]\n",
    "strutture.iloc[:13]\n",
    "strutture.iloc[3:]\n",
    "strutture.iloc[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Comune-di-Roma-Capitale---Elenco-delle-strutture-ricettive.csv'\n",
    "\n",
    "strutture = pd.read_csv(\n",
    "                file_path, \n",
    "                delimiter=';', \n",
    "                encoding='ISO-8859-1'\n",
    "                )\n",
    "\n",
    "strutture.sample() # Restituisce un istanza casuale del DataFrame\n",
    "strutture.sample(5) # Restituisce N istanze casuali del DataFrame\n",
    "strutture.sample(frac=0.1) # Restituisce una percentuale di dati casuali del DataFrame\n",
    "\n",
    "#print(strutture.sample(frac=0.15))\n",
    "print(strutture.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Comune-di-Roma-Capitale---Elenco-delle-strutture-ricettive.csv'\n",
    "\n",
    "strutture = pd.read_csv(\n",
    "                file_path, \n",
    "                delimiter=';', \n",
    "                encoding='ISO-8859-1'\n",
    "                )\n",
    "\n",
    "# Definisco un filtro per estrarre i dati dal DataFrame\n",
    "filtro1 = strutture.Tipologia == \"Albergo\"\n",
    "# Applico il filtro al DataFrame e ottengo un nuovo Dataframe filtrato\n",
    "albergo = strutture.loc[filtro1]\n",
    "#print(albergo.shape)\n",
    "#print(albergo)\n",
    "\n",
    "filtro2 = strutture.Classificazione == \"4 Stelle\"\n",
    "# E' possibile concatenare più filtri utilizzando gli operatori logici\n",
    "# & -> AND \n",
    "# | -> OR \n",
    "# ~ -> NOT\n",
    "albergo4stelle = strutture.loc[filtro1 & filtro2]\n",
    "# print(albergo4stelle.shape)\n",
    "# print(albergo4stelle)\n",
    "\n",
    "filtro3 = strutture.loc[:, \"Posti letto\"] >= 20\n",
    "albergo4stelle20postiletto = strutture.loc[(filtro1 & filtro2) | ~filtro3]\n",
    "\n",
    "print(albergo4stelle20postiletto.shape)\n",
    "albergo4stelle20postiletto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://football-data.co.uk/italym.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "# estrazione di dati tramite un filtro\n",
    "team = data.loc[(data.HomeTeam == \"Milan\") & (data.FTHG >= 2)]\n",
    "\n",
    "# estrazione di dati tramite query()\n",
    "team = data.query(\"HomeTeam == 'Milan' AND FTHG >= 2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "data.sort_index() # ordina i dati in base all'indice - valore di default\n",
    "orderData = data.sort_index(ascending=False) # Ordina in base all'indice discendente \n",
    "data.sort_index(axis=1) # axis = 0 ordina le righe | 1 ordina le colonne\n",
    "data.sort_index(axis=1, ascending= False) # ordino le colonne discendente\n",
    "data.sort_index(ascending=False, inplace=True) # inplace=True rende permanenti le modifiche fatte sul DataFrame\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "# rename permette di rinominare le colonne di un dataFrame\n",
    "data.rename(columns = {\"FTHG\": \"RetiCasa\", \"FTAG\": \"RetiTrasferta\"},\n",
    "            inplace = True)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "data.rename(columns = {\"FTHG\": \"RetiCasa\", \"FTAG\": \"RetiTrasferta\"},\n",
    "            inplace = True)\n",
    "# sort_values ordina i dati in base al valore di una o piu colonne\n",
    "data.sort_values([\"RetiCasa\", \"RetiTrasferta\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "data.rename(columns = {\"FTHG\": \"RetiCasa\", \"FTAG\": \"RetiTrasferta\"},\n",
    "            inplace = True)\n",
    "\n",
    "# value_counts() mi permette di contare i valori di una colonna\n",
    "data.RetiCasa.value_counts()\n",
    "data.Time.value_counts()\n",
    "data.RetiCasa.value_counts(normalize=True) # con normalize=True abbiamo dei risultati in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "# groupby(col) ragruppa i dati del dataFrame in base ad una colonna\n",
    "g = data.groupby(\"HomeTeam\")\n",
    "# g = data.groupby([\"HomeTeam\", \"AwayTeam\"])\n",
    "# get_group(val) seleziona e restituisce uno specifico gruppo\n",
    "g.get_group(\"Roma\")\n",
    "g.get_group(\"Milan\")\n",
    "g.get_group(\"Torino\")\n",
    "# describe() restituisce dati statistici sul dataframe selezionato\n",
    "data.describe()\n",
    "g.describe()\n",
    "# su i gruppi restituiti dal groupby possiamo leggere valori min, max e mean di ogni colonna\n",
    "g.FTHG.min()\n",
    "g.FTHG.max()\n",
    "g.FTHG.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "# mi permettono di sovrascrivere dei valori specificando num di riga e colonna\n",
    "#  at[] utilizza le etichette per selezionare la colonna\n",
    "# iat[] utilizza l'indice per selezionare la colonna\n",
    "data.at[0, 'FTHG'] = 100\n",
    "data.iat[0, 6] = 200\n",
    "\n",
    "new_data = {\n",
    "    \"Div\": 'I1',\n",
    "    \"Date\": '17/09/2024',\n",
    "    \"Time\": '11:50',\n",
    "    \"HomeTeam\": 'Tim',\n",
    "    \"AwayTeam\": 'ITS',\n",
    "    \"FTHG\": 1,\n",
    "    \"FTAG\": 2\n",
    "}\n",
    "\n",
    "new_row = pd.Series(new_data)\n",
    "\n",
    "# append è un metodo deprecato\n",
    "# data.append(new_row)\n",
    "# concat è la soluzione da preferire al posto di append\n",
    "data = pd.concat([data, pd.DataFrame([new_row])], ignore_index=True)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Season_2023_2024_SerieA.csv'\n",
    "data = pd.read_csv(file_path, delimiter=',', encoding='ISO-8859-1')\n",
    "\n",
    "# definisco una funzione con della logica \n",
    "def miaFunc(param):\n",
    "    # logica della funzione\n",
    "    # estraggo l'anno da una data\n",
    "    return param[6:]\n",
    "\n",
    "# applico la funzione ad un DataFrame\n",
    "data.Date.apply(miaFunc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"irisNull.csv\")\n",
    "\n",
    "# metodi predefiniti di python per la pulizia dei dati\n",
    "# isnull()\n",
    "# dropna()\n",
    "# fillna()\n",
    "\n",
    "print(data.shape)\n",
    "data.isnull() # restituisce il dataframe con valori booleani \n",
    "#               sulla presenza di campi null\n",
    "data.isnull().sum() # restituisce un riepilogo di valori di tipo null\n",
    "data.dropna() # elimino le righe con i dati mancanti\n",
    "data.dropna(axis=0) # la proprietà axis 0 elimina le righe con valori mancanti\n",
    "data.dropna(axis=1) # axis 1 elimina le colonne con valori mancanti \n",
    "data.dropna(how=\"any\") # la proprietà how any elimina la riga se almeno un valore è mancante\n",
    "data.dropna(how=\"all\") # how all elimina una riga solo se tutti i valori della riga sono mancanti\n",
    "data.dropna(thresh=2) # viene utilizzata per rimuovere righe o colonne che hanno meno di N valore non NAN\n",
    "\n",
    "data.fillna(10) # Sostituisce i valori mancanti con il valore passato tra gli argomenti della funzione\n",
    "data.fillna({'variety': \"Sconosciuto\", 'petal.length': 10 })\n",
    "data.ffill() # Sostituisce i valori mancanti con quelli della riga precedente\n",
    "data.bfill() # Sostituisce i valori mancanti con quelli della riga successiva\n",
    "data.fillna(data.mean(numeric_only=True)) # Sostituisce i valori mancanti con la media dei valori della colonna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"irisNull.csv\")\n",
    "\n",
    "ldata = { 'c': [\"uno\", \"due\", \"tre\", \"quattro\"], 'val': [1,2,3,4] } \n",
    "rdata = { 'c': [\"uno\", \"due\", \"tre\", \"cinque\"], 'val': [5,6,7,8] }\n",
    "\n",
    "leftData = pd.DataFrame(ldata)\n",
    "rightData = pd.DataFrame(rdata)\n",
    "print(leftData)\n",
    "print(rightData)\n",
    "\n",
    "# Merge permette di fare il join tra dataset simili.\n",
    "# inner, left, right, outer sono l'equivalente dei JOIN SQL\n",
    "pd.merge(left=leftData, right=rightData, on='c', how=\"inner\")\n",
    "pd.merge(left=leftData, right=rightData, on='c', how=\"left\")\n",
    "pd.merge(left=leftData, right=rightData, on='c', how=\"right\")\n",
    "pd.merge(left=leftData, right=rightData, on='c', how=\"outer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
